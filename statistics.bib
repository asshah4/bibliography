Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Steenland2004a,
abstract = {Dose-response modeling in occupational epidemiology is usually motivated by questions of causal inference (eg, is there a monotonic increase of risk with increasing exposure?) or risk assessment (eg, how much excess risk exists at any given level of exposure?). We focus on several approaches to dose-response in occupational cohort studies. Categorical analyses are useful for detecting the shape of dose-response. However, they depend on the number and location of cutpoints and result in step functions rather than smooth curves. Restricted cubic splines and penalized splines are useful parametric techniques that provide smooth curves. Although splines can complement categorical analyses, they do not provide interpretable parameters. The shapes of these curves will depend on the degree of "smoothing" chosen by the analyst. We recommend combining categorical analyses and some type of smoother, with the goal of developing a reasonably simple parametric model. A simple parametric model should serve as the goal of dose-response analyses because (1) most "true" exposure response curves in nature may be reasonably simple, (2) a simple parametric model is easily communicated and used by others, and (3) a simple parametric model is the best tool for risk assessors and regulators seeking to estimate individual excess risks per unit of exposure. We discuss these issues and others, including whether the best model is always the one that fits the best, reasons to prefer a linear model for risk in the low-exposure region when conducting risk assessment, and common methods of calculating excess lifetime risk at a given exposure from epidemiologic results (eg, from rate ratios). Points are illustrated using data from a study of dioxin and cancer.},
author = {Steenland, Kyle and Deddens, James A},
doi = {10.1097/01.ede.0000100287.45004.e7},
file = {:Users/shahbook/Box Sync/Mendeley_Articles/2004 - Steenland, Deddens - A practical guide to dose-response analyses and risk assessment in occupational epidemiology.pdf:pdf},
isbn = {1044-3983},
issn = {10443983},
journal = {Epidemiology},
number = {1},
pages = {63--70},
pmid = {14712148},
title = {{A practical guide to dose-response analyses and risk assessment in occupational epidemiology}},
url = {https://www-jstor-org.proxy.library.emory.edu/stable/pdf/20485841.pdf?refreqid=excelsior%3A28af76a4416a5e5cb55810507358b4a5},
volume = {15},
year = {2004}
}
@misc{Hubbard2010,
abstract = {... To GEE or Not to GEE : Comparing Population Average and Mixed Models for Estimating the Associations Between Neighborhood Risk Factors and Health. Hubbard , Alan E. a ; Ahern, Jennifer b ; Fleischer, Nancy L. b ; Laan, Mark Van der a ; Lippman, Sheri A. b ; Jewell ...},
author = {Hubbard, Alan E. and Ahern, Jennifer and Fleischer, Nancy L. and der Laan, Mark Van and Lippman, Sheri A. and Jewell, Nicholas and Bruckner, Tim and Satariano, William A.},
booktitle = {Epidemiology},
doi = {10.1097/EDE.0b013e3181caeb90},
file = {:Users/shahbook/Box Sync/Mendeley_Articles/2010 - Hubbard et al. - To GEE or not to GEE Comparing population average and mixed models for estimating the associations between neigh.pdf:pdf},
isbn = {1531-5487},
issn = {10443983},
month = {jul},
number = {4},
pages = {467--474},
pmid = {20220526},
title = {{To GEE or not to GEE: Comparing population average and mixed models for estimating the associations between neighborhood risk factors and health}},
url = {https://insights.ovid.com/crossref?an=00001648-201007000-00007},
volume = {21},
year = {2010}
}
@article{Carlin2005,
abstract = {Twin studies have long been recognized for their value in learning about the aetiology of disease and specifically for their potential for separating genetic effects from environmental effects. The recent upsurge of interest in life-course epidemiology and the study of developmental influences on later health has provided a new impetus to study twins as a source of unique insights. Twins are of special interest because they provide naturally matched pairs where the confounding effects of a large number of potentially causal factors (such as maternal nutrition or gestation length) may be removed by comparisons between twins who share them. The traditional tool of epidemiological ‘risk factor analysis' is the regression model, but it is not straightforward to transfer standard regression methods to twin data, because the analysis needs to reflect the paired structure of the data, which induces correlation between twins. This paper reviews the use of more specialized regression methods for twin data, based on generalized least squares or linear mixed models, and explains the relationship between these methods and the commonly used approach of analysing within-twin-pair difference values. Methods and issues of interpretation are illustrated using an example from a recent study of the association between birth weight and cord blood erythropoietin. We focus on the analysis of continuous outcome measures but review additional complexities that arise with binary outcomes. We recommend the use of a general model that includes separate regression coefficients for within-twin-pair and between-pair effects, and provide guidelines for the interpretation of estimates obtained under this model.},
author = {Carlin, John B and Gurrin, Lyle C and Sterne, Jonathan A C and Morley, Ruth and Dwyer, Terry},
doi = {10.1093/ije/dyi153},
file = {:Users/shahbook/Box Sync/Mendeley_Articles/2005 - Carlin et al. - Regression models for twin studies A critical review.pdf:pdf},
isbn = {0300-5771 (Print)\r0300-5771},
issn = {03005771},
journal = {International Journal of Epidemiology},
keywords = {Data correlation,Regression models,Statistics,Twin studies},
number = {5},
pages = {1089--1099},
pmid = {16087687},
title = {{Regression models for twin studies: A critical review}},
volume = {34},
year = {2005}
}
@article{Desquilbet2010,
abstract = {Taking into account a continuous exposure in regression models by using categorization, when non-linear dose-response associations are expected, have been widely criticized. As one alternative, restricted cubic spline (RCS) functions are powerful tools (i) to characterize a dose-response association between a continuous exposure and an outcome, (ii) to visually and/or statistically check the assumption of linearity of the association, and (iii) to minimize residual confounding when adjusting for a continuous exposure. Because their implementation with SAS{\textregistered} software is limited, we developed and present here an SAS macro that (i) creates an RCS function of continuous exposures, (ii) displays graphs showing the dose-response association with 95 per cent confidence interval between one main continuous exposure and an outcome when performing linear, logistic, or Cox models, as well as linear and logistic-generalized estimating equations, and (iii) provides statistical tests for overall and non-linear associations. We illustrate the SAS macro using the third National Health and Nutrition Examination Survey data to investigate adjusted dose-response associations (with different models) between calcium intake and bone mineral density (linear regression), folate intake and hyperhomocysteinemia (logistic regression), and serum high-density lipoprotein cholesterol and cardiovascular mortality (Cox model).},
author = {Desquilbet, Loic and Mariotti, Fran{\c{c}}ois},
doi = {10.1002/sim.3841},
file = {:Users/shahbook/Box Sync/Mendeley_Articles/2010 - Desquilbet, Mariotti - Dose-response analyses using restricted cubic spline functions in public health research.pdf:pdf},
isbn = {1097-0258},
issn = {02776715},
journal = {Statistics in Medicine},
number = {9},
pages = {1037--1057},
pmid = {20087875},
title = {{Dose-response analyses using restricted cubic spline functions in public health research}},
volume = {29},
year = {2010}
}
@article{Austin2006,
abstract = {Objectives: To illustrate how multiple hypotheses testing can produce associations with no clinical plausibility. Study Design and Setting: We conducted a study of all 10,674,945 residents of Ontario aged between 18 and 100 years in 2000. Residents were randomly assigned to equally sized derivation and validation cohorts and classified according to their astrological sign. Using the derivation cohort, we searched through 223 of the most common diagnoses for hospitalization until we identified two for which subjects born under one astrological sign had a significantly higher probability of hospitalization compared to subjects born under the remaining signs combined (P < 0.05). Results: We tested these 24 associations in the independent validation cohort. Residents born under Leo had a higher probability of gastrointestinal hemorrhage (P = 0.0447), while Sagittarians had a higher probability of humerus fracture (P = 0.0123) compared to all other signs combined. After adjusting the significance level to account for multiple comparisons, none of the identified associations remained significant in either the derivation or validation cohort. Conclusions: Our analyses illustrate how the testing of multiple, non-prespecified hypotheses increases the likelihood of detecting implausible associations. Our findings have important implications for the analysis and interpretation of clinical studies. {\textcopyright} 2006 Elsevier Inc. All rights reserved.},
author = {Austin, Peter C. and Mamdani, Muhammad M. and Juurlink, David N. and Hux, Janet E.},
doi = {10.1016/j.jclinepi.2006.01.012},
file = {:Users/shahbook/Box Sync/Mendeley_Articles//2006 - Austin et al. - Testing multiple statistical hypotheses resulted in spurious associations a study of astrological signs and healt.pdf:pdf},
isbn = {0895-4356 (Print)},
issn = {08954356},
journal = {Journal of Clinical Epidemiology},
keywords = {Astrology,Data mining,Hypothesis testing,Multiple comparisons,Statistical methods,Subgroup analyses},
month = {sep},
number = {9},
pages = {964--969},
pmid = {16895820},
publisher = {Pergamon},
title = {{Testing multiple statistical hypotheses resulted in spurious associations: a study of astrological signs and health}},
url = {https://www-sciencedirect-com.proxy.library.emory.edu/science/article/pii/S0895435606001247?via%3Dihub https://ac-els-cdn-com.proxy.library.emory.edu/S0895435606001247/1-s2.0-S0895435606001247-main.pdf?_tid=177881df-b779-4b6a-ad7b-221f66c904ca&acdnat=1535},
volume = {59},
year = {2006}
}
@article{Blume2018,
abstract = {Verifying that a statistically significant result is scientifically meaningful is not only good scientific practice, it is a natural way to control the Type I error rate. Here we introduce a novel extension of the p-value—a second-generation p-value (p$\delta$)–that formally accounts for scientific relevance and leverages this natural Type I Error control. The approach relies on a pre-specified interval null hypothesis that represents the collection of effect sizes that are scientifically uninteresting or are practically null. The second-generation p-value is the proportion of data-supported hypotheses that are also null hypotheses. As such, second-generation p-values indicate when the data are compatible with null hypotheses (p$\delta$ = 1), or with alternative hypotheses (p$\delta$ = 0), or when the data are inconclusive (0 < p$\delta$ < 1). Moreover, second-generation p-values provide a proper scientific adjustment for multiple comparisons and reduce false discovery rates. This is an advance for environments rich in data, where traditional p-value adjustments are needlessly punitive. Second-generation p-values promote transparency, rigor and reproducibility of scientific results by a priori specifying which candidate hypotheses are practically meaningful and by providing a more reliable statistical summary of when the data are compatible with alternative or null hypotheses.},
archivePrefix = {arXiv},
arxivId = {1709.09333},
author = {Blume, Jeffrey D. and {D'Agostino McGowan}, Lucy and Dupont, William D. and Greevy, Robert A.},
doi = {10.1371/journal.pone.0188299},
editor = {Smalheiser, Neil R.},
eprint = {1709.09333},
file = {:Users/shahbook/Box Sync/Mendeley_Articles/2018 - Blume et al. - Second-generation p-values Improved rigor, reproducibility, & transparency in statistical analyses.pdf:pdf},
isbn = {1111111111},
issn = {19326203},
journal = {PLoS ONE},
month = {mar},
number = {3},
pages = {e0188299},
pmid = {29565985},
publisher = {Public Library of Science},
title = {{Second-generation p-values: Improved rigor, reproducibility, & transparency in statistical analyses}},
url = {http://dx.plos.org/10.1371/journal.pone.0188299},
volume = {13},
year = {2018}
}
@article{Lo2015,
abstract = {Thus far, genome-wide association studies (GWAS) have been disappointing in the inability of investigators to use the results of identified, statistically significant variants in complex diseases to make predictions useful for personalized medicine. Why are significant variables not leading to good prediction of outcomes? We point out that this problem is prevalent in simple as well as complex data, in the sciences as well as the social sciences. We offer a brief explanation and some statistical insights on why higher significance cannot automatically imply stronger predictivity and illustrate through simulations and a real breast cancer example. We also demonstrate that highly predictive variables do not necessarily appear as highly significant, thus evading the researcher using significance-based methods. We point out that what makes variables good for prediction versus significance depends on different properties of the underlying distributions. If prediction is the goal, we must lay aside significance as the only selection standard. We suggest that progress in prediction requires efforts toward a new research agenda of searching for a novel criterion to retrieve highly predictive variables rather than highly significant variables. We offer an alternative approach that was not designed for significance, the partition retention method, which was very effective predicting on a long-studied breast cancer data set, by reducing the classification error rate from 30% to 8%.},
author = {Lo, Adeline and Chernoff, Herman and Zheng, Tian and Lo, Shaw-Hwa},
doi = {10.1073/pnas.1518285112},
file = {:Users/shahbook/Box Sync/Mendeley_Articles/2015 - Lo et al. - Why significant variables aren't automatically good predictors.pdf:pdf},
isbn = {1518285112},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
number = {45},
pages = {13892--13897},
pmid = {26504198},
title = {{Why significant variables aren't automatically good predictors}},
url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1518285112},
volume = {112},
year = {2015}
}
@unpublished{Racine2018,
abstract = {1. Overview B-splines constitute an appealing method for the nonparametric estimation of a range of statis-tical objects of interest. In this primer we focus our attention on the estimation of a conditional mean, i.e. the 'regression function'. A 'spline' is a function that is constructed piece-wise from polynomial functions. The term comes from the tool used by shipbuilders and drafters to construct smooth shapes having desired properties. Drafters have long made use of a bendable strip fixed in position at a number of points that relaxes to form a smooth curve passing through those points. The malleability of the spline material combined with the constraint of the control points would cause the strip to take the shape that minimized the energy required for bending it between the fixed points, this being the smoothest possible shape. We shall rely on a class of splines called 'B-splines' ('basis-splines'). A B-spline function is the maximally differentiable interpolative basis function. The B-spline is a generalization of the B{\'{e}}zier curve (a B-spline with no 'interior knots' is a B{\'{e}}zier curve). B-splines are defined by their 'order' m and number of interior 'knots' N (there are two 'endpoints' which are themselves knots so the total number of knots will be N +2). The degree of the B-spline polynomial will be the spline order m minus one (degree = m − 1). To best appreciate the nature of B-splines, we shall first consider a simple type of spline, the B{\'{e}}zier function, and then move on to the more flexible and powerful generalization, the B-spline itself. We begin with the univariate case in Section 2 where we consider the univariate B{\'{e}}zier function. In Section 3 we turn to the univariate B-spline function, and then in Section 4 we turn to the multivariate case where we also briefly mention how one could handle the presence of categorical predictors. We presume that interest lies in 'regression spline' methodology which differs in a number of ways from 'smoothing splines', both of which are popular in applied settings. The fundamen-tal difference between the two approaches is that smoothing splines explicitly penalize roughness and use the data points themselves as potential knots whereas regression splines place knots at equidistant/equiquantile points. We direct the interested reader to Wahba (1990) for a treatment of smoothing splines. Date: December 18, 2014. These notes are culled from a variety of sources. I am solely responsible for all errors. Suggestions are welcomed (racinej@mcmaster.ca). 1 2 JEFFREY S. RACINE 2. B{\'{e}}zier curves We present an overview of B{\'{e}}zier curves which form the basis for the B-splines that follow. We begin with a simple illustration, that of a quadratic B{\'{e}}zier curve. Example 2.1. A quadratic B{\'{e}}zier curve. A quadratic B{\'{e}}zier curve is the path traced by the function B(x), given points $\beta$ 0 , $\beta$ 1 , and $\beta$ 2 , where B(x) = $\beta$ 0 (1 − x) 2 + 2$\beta$ 1 (1 − x)x + $\beta$ 2 x 2 = 2 i=0 $\beta$ i B i (x), x ∈ [0, 1]. The terms B 0 (x) = (1 − x) 2 , B 1 (x) = 2(1 − x)x, and B 2 (x) = x 2 are the 'bases' which is this case turn out to be 'Bernstein polynomials' (Bernstein (1912)). For our purposes the 'control points' $\beta$ i , i = 0, 1, 2, will be parameters that could be selected by least squares fitting in a regression setting, but more on that later. Consider the following simple example where we plot a quadratic B{\'{e}}zier curve with arbitrary control points: 0.0 0.2 0.4 0.6 0.8 1.0},
author = {Racine, Jeffrey S},
booktitle = {CRAN. R-Project.},
doi = {10.1177/1094428104272636},
file = {:Users/shahbook/Box Sync/Mendeley_Articles/2018 - Racine - A primer on regression splines.pdf:pdf},
isbn = {0031-5826},
issn = {10944281},
pages = {1--11},
title = {{A primer on regression splines}},
url = {https://cran.r-project.org/web/packages/crs/vignettes/spline_primer.pdf http://cran.md.tsukuba.ac.jp/web/packages/crs/vignettes/spline_primer.pdf},
year = {2018}
}
@article{Dupont1998,
abstract = {This article presents methods for sample size and power calculations for studies involving linear regression. These approaches are applicable to clinical trials designed to detect a regression slope of a given magnitude or to studies that test whether the slopes or intercepts of two independent regression lines differ by a given amount. The investigator may either specify the values of the independent (x) variable(s) of the regression line(s) or determine them observationally when the study is performed. In the latter case, the investigator must estimate the standard deviation(s) of the independent variable(s). This study gives examples using this method for both experimental and observational study designs. Cohen's method of power calculations for multiple linear regression models is also discussed and contrasted with the methods of this study. We have posted a computer program to perform these and other sample size calculations on the Internet (see http://www.mc.vanderbilt.edu/prevmed/psintro.htm). This program can determine the sample size needed to detect a specified alternative hypothesis with the required power, the power with which a specific alternative hypothesis can be detected with a given sample size, or the specific alternative hypotheses that can be detected with a given power and sample size. Context-specific help messages available on request make the use of this software largely self-explanatory. Copyright (C) 1998 Elsevier Science Inc.},
author = {Dupont, William D. and Plummer, Walton D.},
doi = {10.1016/S0197-2456(98)00037-3},
isbn = {0197-2456},
issn = {01972456},
journal = {Controlled Clinical Trials},
keywords = {Linear models,Linear regression,Power calculations,Regression analysis,Sample size calculations,Statistics},
month = {dec},
number = {6},
pages = {589--601},
pmid = {9875838},
publisher = {Elsevier},
title = {{Power and sample size calculations for studies involving linear regression}},
url = {https://www.sciencedirect.com/science/article/pii/S0197245698000373},
volume = {19},
year = {1998}
}
@article{Bates2015,
author = {Bates, Douglas and M{\"{a}}chler, Martin and Bolker, Ben and Walker, Steve},
doi = {10.18637/jss.v067.i01},
journal = {Journal of Statistical Software},
number = {1},
pages = {1--48},
title = {{Fitting Linear Mixed-Effects Models Using {lme4}}},
volume = {67},
year = {2015}
}
@article{Joe2008,
abstract = {The Laplace approximation is amongst the computational methods used for estimation in generalized linear mixed models. It is computationally the fastest, but there hasn't been a clear analysis of when its accuracy is adequate. In this paper, for a few factors we do calculations for a variety of mixed models to show patterns in the asymptotic bias of the estimator based on the maximum of the Laplace approximation of the log-likelihood. The biggest factor for asymptotic bias is the amount of discreteness in the response variable; there is more bias for binary and ordinal responses than for a count response, and more bias for a count response when its support is mainly near 0. When there is bias, the bias decreases as the cluster size increases. Often, the Laplace approximation is adequate even for small cluster sizes. Even with bias, the Laplace approximation may be adequate for quick assessment of competing mixed models with different random effects and covariates. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
author = {Joe, Harry},
doi = {10.1016/j.csda.2008.05.002},
file = {:Users/shahbook/Box Sync/Mendeley_Articles/2008 - Joe - Accuracy of Laplace approximation for discrete response mixed models.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
month = {aug},
number = {12},
pages = {5066--5074},
publisher = {North-Holland},
title = {{Accuracy of Laplace approximation for discrete response mixed models}},
url = {https://www-sciencedirect-com.proxy.library.emory.edu/science/article/pii/S0167947308002533},
volume = {52},
year = {2008}
}
@article{Mark2016,
abstract = {Pvalues and hypothesis testing methods are frequently misused in clinical research. Much of this misuse appears to be owing to the widespread, mistaken belief that they provide simple, reliable, and objective triage tools for separating the true and important from the untrue or unimportant. The primary focus in interpreting therapeutic clinical research data should be on the treatment (“oomph”) effect, a metaphorical force that moves patients given an effective treatment to a different clinical state relative to their control counterparts. This effect is assessed using 2 complementary types of statistical measures calculated from the data, namely, effect magnitude or size and precision of the effect size. In a randomized trial, effect size is often summarized using constructs, such as odds ratios, hazard ratios, relative risks, or adverse event rate differences. How large a treatment effect has to be to be consequential is a matter for clinical judgment. The precision of the effect size (conceptually related to the amount of spread in the data) is usually addressed with confidence intervals.Pvalues (significance tests) were first proposed as an informal heuristic to help assess how “unexpected” the observed effect size was if the true state of nature was no effect or no difference. Hypothesis testing was a modification of the significance test approach that envisioned controlling the false-positive rate of study results over many (hypothetical) repetitions of the experiment of interest. Both can be helpful but, by themselves, provide only a tunnel vision perspective on study results that ignores the clinical effects the study was conducted to measure.},
author = {Mark, Daniel B. and Lee, Kerry L. and Harrell, Frank E.},
doi = {10.1001/jamacardio.2016.3312},
file = {:Users/shahbook/Box Sync/Mendeley_Articles/2016 - Mark, Lee, Harrell - Understanding the role of P values and hypothesis tests in clinical research.pdf:pdf},
isbn = {2380-6591 (Electronic)},
issn = {23806591},
journal = {JAMA Cardiology},
keywords = {adverse event,clinical research,false-positive results,hypothesis testing,null hypothesis testing,p-value,statistical tests},
month = {dec},
number = {9},
pages = {1048--1054},
pmid = {27732700},
publisher = {American Medical Association},
title = {{Understanding the role of P values and hypothesis tests in clinical research}},
url = {http://cardiology.jamanetwork.com/article.aspx?doi=10.1001/jamacardio.2016.3312},
volume = {1},
year = {2016}
}
@article{Sullivan2012,
abstract = {Statistical significance is the least interesting thing about the results. You should describe the results in terms of measures of magnitude –not just, does a treatment affect people, but how much does it affect them. The primary product of a research inquiry is one or more measures of effect size, not P values.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Sullivan, Gail M and Feinn, Richard},
doi = {10.4300/JGME-D-12-00156.1},
eprint = {arXiv:1011.1669v3},
isbn = {1949-8349 1949-8357},
issn = {1949-8349},
journal = {Journal of Graduate Medical Education},
month = {sep},
number = {3},
pages = {279--282},
pmid = {23997866},
publisher = {Accreditation Council for Graduate Medical Education},
title = {{Using Effect Size—or Why the P Value Is Not Enough}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23997866 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3444174 http://www.jgme.org/doi/abs/10.4300/JGME-D-12-00156.1},
volume = {4},
year = {2012}
}
@article{Lee2016,
abstract = {The previous articles of the Statistical Round in the Korean Journal of Anesthesiology posed a strong enquiry on the issue of null hypothesis significance testing (NHST). P values lie at the core of NHST and are used to classify all treatments into two groups: "has a significant effect" or "does not have a significant effect." NHST is frequently criticized for its misinterpretation of relationships and limitations in assessing practical importance. It has now provoked criticism for its limited use in merely separating treatments that "have a significant effect" from others that do not. Effect sizes and CIs expand the approach to statistical thinking. These attractive estimates facilitate authors and readers to discriminate between a multitude of treatment effects. Through this article, I have illustrated the concept and estimating principles of effect sizes and CIs.},
author = {Lee, Dong Kyu},
doi = {10.4097/kjae.2016.69.6.555},
issn = {20057563},
journal = {Korean Journal of Anesthesiology},
keywords = {Confidence intervals,Effect sizes,P value},
month = {dec},
number = {6},
pages = {555--562},
pmid = {27924194},
publisher = {Korean Society of Anesthesiologists},
title = {{Alternatives to P value: Confidence interval and effect size}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/27924194 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5133225},
volume = {69},
year = {2016}
}
@article{Diamond2013,
abstract = {Published reports of randomized clinical trials tend to emphasize the statistical significance of the treatment effect (p values) rather than its magnitude (effect size), although the clinical importance of the evidence depends more on the latter than on the former. We, therefore, compared the standard measures of effect size (relative and absolute risk reduction) and nonstandard composites of these measures (the product of the relative and absolute risk reductions and information content) with conventional assessments of statistical significance for 100 trials published in The New England Journal of Medicine. The p values were reported for 100% of the trials, relative risk reductions for 89%, and absolute risk reductions for 39%. Only 35% of trials reported both standard measures, and none reported either of the nonstandard measures. The standard measures correlated weakly (unexplained variance 77%). In contrast, the nonstandard measures correlated highly (unexplained variance 1.3%) but correlated weakly with statistical significance (unexplained variance 83%). Consequently, 25% of the trial results were adjudged "clinically unimportant" despite being "statistically significant." In conclusion, our results have shown that composite measures of effect size communicate the clinical importance of trial results better than do conventional assessments of risk reduction and statistical significance. {\textcopyright} 2013 Elsevier Inc. All rights reserved.},
author = {Diamond, George A. and Kaul, Sanjay},
doi = {10.1016/j.amjcard.2012.10.047},
file = {:Users/shahbook/Box Sync/Mendeley_Articles/2013 - Diamond, Kaul - On reporting of effect size in randomized clinical trials.pdf:pdf},
issn = {00029149},
journal = {American Journal of Cardiology},
month = {feb},
number = {4},
pages = {613--617},
publisher = {Excerpta Medica},
title = {{On reporting of effect size in randomized clinical trials}},
url = {https://www-sciencedirect-com.proxy.library.emory.edu/science/article/pii/S000291491202334X?via%3Dihub},
volume = {111},
year = {2013}
}
@article{Szumilas2010,
abstract = {Understandig Odds Ratio},
author = {Szumilas, Magdalena},
doi = {10.1136/bmj.c4414},
file = {:Users/shahbook/Box Sync/Mendeley_Articles/2010 - Szumilas - Explaining odds ratios.pdf:pdf},
isbn = {1719-8429},
issn = {17198429},
journal = {Journal of the Canadian Academy of Child and Adolescent Psychiatry},
month = {aug},
number = {3},
pages = {227--229},
pmid = {20842279},
publisher = {Canadian Academy of Child and Adolescent Psychiatry},
title = {{Explaining odds ratios}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20842279 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2938757},
volume = {19},
year = {2010}
}
@article{Parsons2009a,
abstract = {The widely used proportional odds model is developed for correlated repeated ordinal score data, using a modified version of the generalized estimating equation (GEE) method for model fitting for a range of working correlation models. The algorithm developed estimates the correlation parameter, by minimizing the generalized variance of the regression parameters at each step of the fitting algorithm. Methods for parameter estimation are described for the widely used uniform and first-order autoregressive correlation models, for data potentially recorded at irregularly spaced time intervals. A full implementation of the algorithm (repolr) in the R statistical software package, that both tests the assumption of proportional odds and accommodates missing data, is described and applied to a clinical trial of post-operative treatment, after rupture of the Achilles tendon and a study of patient pain response after hip joint resurfacing. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
author = {Parsons, Nick R. and Costa, Matthew L. and Achten, Juul and Stallard, Nigel},
doi = {10.1016/j.csda.2008.08.004},
file = {:Users/shahbook/Box Sync/Mendeley_Articles/2009 - Parsons et al. - Repeated measures proportional odds logistic regression analysis of ordinal score data in the statistical softwa.pdf:pdf},
isbn = {2476968617},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
month = {jan},
number = {3},
pages = {632--641},
pmid = {35501265},
publisher = {North-Holland},
title = {{Repeated measures proportional odds logistic regression analysis of ordinal score data in the statistical software package R}},
url = {www.elsevier.com/locate/csda https://www-sciencedirect-com.proxy.library.emory.edu/science/article/pii/S0167947308003939},
volume = {53},
year = {2009}
}
